{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1acdd2-0c54-4553-b1c5-3b5f7663ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  Project: Generative Text Model using GPT-2\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "The goal of this project is to build a **text generation model** capable of producing **coherent and meaningful paragraphs** based on **user-provided prompts or topics**.\n",
    "\n",
    "This is achieved using **GPT-2**, a powerful language model developed by OpenAI and made accessible through Hugging Face Transformers.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Tools & Technologies\n",
    "- **Python** (Jupyter Notebook)\n",
    "- **Hugging Face Transformers** (for GPT-2 model)\n",
    "- **PyTorch** (backend for model inference)\n",
    "- Optional: Streamlit or Gradio (for interactive web UI)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Approach\n",
    "1. Load the **pre-trained GPT-2 model** and tokenizer.\n",
    "2. Take user input (e.g., â€œBenefits of exerciseâ€).\n",
    "3. Tokenize the input and feed it to GPT-2.\n",
    "4. Generate a paragraph based on the prompt using **controlled sampling** techniques like top-k, top-p (nucleus sampling), and temperature.\n",
    "5. Decode and display the generated text.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Key Features\n",
    "- Generates **contextually relevant paragraphs** based on the prompt.\n",
    "- Uses **pre-trained models** (no need for training).\n",
    "- User-friendly and fast.\n",
    "- Can be extended to UI-based applications or APIs.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§¾ Deliverable\n",
    "- A **Jupyter Notebook** demonstrating the full pipeline from loading the model to generating and displaying paragraphs.\n",
    "- This can be used as part of your internship project submission.\n",
    "\n",
    "> ðŸ”– *â€œCompletion Certificate will be issued on your internship end date.â€*  \n",
    "> â€” **CODTECH**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Sample Use Case\n",
    "**Prompt:** â€œImportance of Time Managementâ€  \n",
    "**Output:**  \n",
    "> Time management is a critical skill for achieving personal and professional goals. It allows individuals to prioritize tasks, reduce stress, and maintain a healthy work-life balance. By planning effectively and using time wisely, one can become more productive and successful.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ™Œ Conclusion\n",
    "This project demonstrates the practical power of pre-trained language models like GPT-2 in **natural language generation (NLG)**. It serves as a foundational step into the world of **AI writing assistants, content generation tools, and chatbots**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e62c8c-38cb-4ca8-92e5-b44ef788e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a topic or prompt: importance of time management\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Paragraph:\n",
      "\n",
      "importance of time management in the absence of a simple user interface.\n",
      "\n",
      "But when it comes to design in mobile, the key design language in Apple's App Store is the concept of design flow. That's what gives Apple its \"app flow\" approach to designing user interfaces. And what it means for designers is that if you've created a design that's well thought-out and uses logic in place, then the first steps in building that can be made to work. For Apple, it's much easier to build apps with logic as the designer's job. But if designers don't think of how they're going to write their UI, as well as how to implement that logic, they'll miss out on a few things. On that\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install required libraries (run only once)\n",
    "!pip install transformers --quiet\n",
    "!pip install torch --quiet\n",
    "\n",
    "# Step 2: Import libraries\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Step 3: Load GPT-2 pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # You can also try \"gpt2-medium\" or \"distilgpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Step 4: Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Step 5: Define the text generation function\n",
    "def generate_text(prompt, max_length=150):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        temperature=0.9,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Step 6: Example usage\n",
    "user_prompt = input(\"Enter a topic or prompt:\")\n",
    "output_text = generate_text(user_prompt)\n",
    "print(\"\\nGenerated Paragraph:\\n\")\n",
    "print(output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa25a9c7-f95c-4c44-843e-622e4b19015c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef89603-f9eb-44ec-988c-84c8df8e17df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
